{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import context\n",
    "from ccn import Constraint, ConstraintsGroup\n",
    "from shapes import HalfPlane, Circle\n",
    "from experiment import Experiment\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "h1 = HalfPlane(1, 0, -0.5)\n",
    "h2 = -h1 \n",
    "circle = Circle(0.5, 0.5, 0.20)\n",
    "shapes = [h1 & -circle, circle, h2 & -circle]\n",
    "\n",
    "fig, ax = plt.subplots(1, len(shapes))\n",
    "for i, shape in enumerate(shapes):\n",
    "  shape.plot(ax[i], full=True)\n",
    "plt.show()\n",
    "\n",
    "constraints = [\n",
    "  ConstraintsGroup([Constraint('n0 :- 1')]),\n",
    "  ConstraintsGroup([Constraint('n2 :- 1'), Constraint('2 :- n0 n1')])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(2, 4),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(4, 4),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(4, 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.655831 [    0/10000]\n",
      "loss: 0.364718 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 93.6%, 87.7%, 91.7%\n",
      " Avg loss: 0.004535 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.285393 [    0/10000]\n",
      "loss: 0.260071 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, 87.7%, 90.5%\n",
      " Avg loss: 0.003831 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.224576 [    0/10000]\n",
      "loss: 0.217513 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, 88.1%, 91.8%\n",
      " Avg loss: 0.003686 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.214309 [    0/10000]\n",
      "loss: 0.208985 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 93.7%, 88.2%, 93.3%\n",
      " Avg loss: 0.003637 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.210082 [    0/10000]\n",
      "loss: 0.205282 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, 88.0%, 93.3%\n",
      " Avg loss: 0.003600 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.207801 [    0/10000]\n",
      "loss: 0.202757 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, 87.9%, 93.5%\n",
      " Avg loss: 0.003568 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.206639 [    0/10000]\n",
      "loss: 0.199574 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, 87.5%, 93.0%\n",
      " Avg loss: 0.003536 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.205640 [    0/10000]\n",
      "loss: 0.195162 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 94.6%, 88.1%, 93.1%\n",
      " Avg loss: 0.003464 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.203819 [    0/10000]\n",
      "loss: 0.187445 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 95.1%, 89.0%, 92.7%\n",
      " Avg loss: 0.003367 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.198451 [    0/10000]\n",
      "loss: 0.175271 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 95.8%, 90.6%, 93.2%\n",
      " Avg loss: 0.003161 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.176552 [    0/10000]\n",
      "loss: 0.151369 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, 91.6%, 93.3%\n",
      " Avg loss: 0.002713 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.137557 [    0/10000]\n",
      "loss: 0.109095 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, 94.6%, 95.6%\n",
      " Avg loss: 0.002012 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.091169 [    0/10000]\n",
      "loss: 0.074282 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, 96.3%, 96.5%\n",
      " Avg loss: 0.001548 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.070012 [    0/10000]\n",
      "loss: 0.054318 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, 97.5%, 97.4%\n",
      " Avg loss: 0.001276 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.059709 [    0/10000]\n",
      "loss: 0.043129 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, 97.8%, 97.7%\n",
      " Avg loss: 0.001105 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.053347 [    0/10000]\n",
      "loss: 0.036796 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, 97.8%, 97.7%\n",
      " Avg loss: 0.000997 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.049294 [    0/10000]\n",
      "loss: 0.032907 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, 98.0%, 97.9%\n",
      " Avg loss: 0.000925 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.046185 [    0/10000]\n",
      "loss: 0.029809 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, 97.9%, 97.9%\n",
      " Avg loss: 0.000888 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.044453 [    0/10000]\n",
      "loss: 0.027274 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, 97.7%, 97.4%\n",
      " Avg loss: 0.000847 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.042944 [    0/10000]\n",
      "loss: 0.025101 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, 97.7%, 97.2%\n",
      " Avg loss: 0.000803 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.041173 [    0/10000]\n",
      "loss: 0.023266 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, 97.9%, 97.4%\n",
      " Avg loss: 0.000767 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.039582 [    0/10000]\n",
      "loss: 0.021828 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, 97.7%, 97.2%\n",
      " Avg loss: 0.000741 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.038593 [    0/10000]\n",
      "loss: 0.020579 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, 97.7%, 97.2%\n",
      " Avg loss: 0.000712 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.037616 [    0/10000]\n",
      "loss: 0.019593 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, 97.7%, 97.2%\n",
      " Avg loss: 0.000689 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.037186 [    0/10000]\n",
      "loss: 0.018790 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, 97.9%, 97.5%\n",
      " Avg loss: 0.000654 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.036486 [    0/10000]\n",
      "loss: 0.017986 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, 98.2%, 97.6%\n",
      " Avg loss: 0.000632 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.036988 [    0/10000]\n",
      "loss: 0.017236 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, 98.3%, 97.7%\n",
      " Avg loss: 0.000611 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.038166 [    0/10000]\n",
      "loss: 0.016578 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, 98.3%, 97.8%\n",
      " Avg loss: 0.000592 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.039905 [    0/10000]\n",
      "loss: 0.015893 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, 98.5%, 98.0%\n",
      " Avg loss: 0.000570 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.041315 [    0/10000]\n",
      "loss: 0.015316 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, 98.5%, 98.1%\n",
      " Avg loss: 0.000550 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.042335 [    0/10000]\n",
      "loss: 0.014727 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, 98.6%, 98.2%\n",
      " Avg loss: 0.000532 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.042919 [    0/10000]\n",
      "loss: 0.014241 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, 98.7%, 98.3%\n",
      " Avg loss: 0.000516 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.043097 [    0/10000]\n",
      "loss: 0.013876 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, 98.9%, 98.4%\n",
      " Avg loss: 0.000499 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.042940 [    0/10000]\n",
      "loss: 0.013506 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, 98.9%, 98.4%\n",
      " Avg loss: 0.000483 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.042434 [    0/10000]\n",
      "loss: 0.013239 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, 98.9%, 98.5%\n",
      " Avg loss: 0.000469 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.041916 [    0/10000]\n",
      "loss: 0.012972 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, 98.9%, 98.5%\n",
      " Avg loss: 0.000456 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.041561 [    0/10000]\n",
      "loss: 0.012781 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, 99.1%, 98.7%\n",
      " Avg loss: 0.000443 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.041035 [    0/10000]\n",
      "loss: 0.012628 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, 99.0%, 98.7%\n",
      " Avg loss: 0.000431 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.040411 [    0/10000]\n",
      "loss: 0.012507 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, 99.0%, 98.8%\n",
      " Avg loss: 0.000421 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.039899 [    0/10000]\n",
      "loss: 0.012399 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, 99.1%, 98.8%\n",
      " Avg loss: 0.000412 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.039497 [    0/10000]\n",
      "loss: 0.012299 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, 99.1%, 98.8%\n",
      " Avg loss: 0.000403 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.039014 [    0/10000]\n",
      "loss: 0.012209 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, 99.2%, 98.9%\n",
      " Avg loss: 0.000395 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.038532 [    0/10000]\n",
      "loss: 0.012122 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, 99.3%, 99.1%\n",
      " Avg loss: 0.000387 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.038044 [    0/10000]\n",
      "loss: 0.012039 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, 99.3%, 99.1%\n",
      " Avg loss: 0.000380 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.037565 [    0/10000]\n",
      "loss: 0.011959 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, 99.3%, 99.1%\n",
      " Avg loss: 0.000373 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.037098 [    0/10000]\n",
      "loss: 0.011879 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, 99.4%, 99.2%\n",
      " Avg loss: 0.000365 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.036454 [    0/10000]\n",
      "loss: 0.011805 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, 99.4%, 99.2%\n",
      " Avg loss: 0.000359 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.035983 [    0/10000]\n",
      "loss: 0.011758 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, 99.4%, 99.2%\n",
      " Avg loss: 0.000353 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.035555 [    0/10000]\n",
      "loss: 0.011678 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, 99.4%, 99.2%\n",
      " Avg loss: 0.000348 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.035115 [    0/10000]\n",
      "loss: 0.011637 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, 99.4%, 99.2%\n",
      " Avg loss: 0.000342 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.034664 [    0/10000]\n",
      "loss: 0.011549 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, 99.4%, 99.2%\n",
      " Avg loss: 0.000337 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.034227 [    0/10000]\n",
      "loss: 0.011463 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, 99.5%, 99.3%\n",
      " Avg loss: 0.000332 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.033798 [    0/10000]\n",
      "loss: 0.011379 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, 99.5%, 99.3%\n",
      " Avg loss: 0.000327 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.033346 [    0/10000]\n",
      "loss: 0.011297 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, 99.5%, 99.3%\n",
      " Avg loss: 0.000323 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.032932 [    0/10000]\n",
      "loss: 0.011216 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, 99.5%, 99.3%\n",
      " Avg loss: 0.000318 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.032528 [    0/10000]\n",
      "loss: 0.011136 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, 99.5%, 99.3%\n",
      " Avg loss: 0.000314 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.032130 [    0/10000]\n",
      "loss: 0.011059 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, 99.5%, 99.3%\n",
      " Avg loss: 0.000310 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.031744 [    0/10000]\n",
      "loss: 0.011009 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, 99.4%, 99.3%\n",
      " Avg loss: 0.000311 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.033271 [    0/10000]\n",
      "loss: 0.010969 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, 99.4%, 99.3%\n",
      " Avg loss: 0.000307 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.032731 [    0/10000]\n",
      "loss: 0.010912 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, 99.4%, 99.3%\n",
      " Avg loss: 0.000303 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.032339 [    0/10000]\n",
      "loss: 0.010844 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, 99.5%, 99.4%\n",
      " Avg loss: 0.000300 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.032003 [    0/10000]\n",
      "loss: 0.010772 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, 99.5%, 99.4%\n",
      " Avg loss: 0.000297 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.031716 [    0/10000]\n",
      "loss: 0.010700 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, 99.5%, 99.4%\n",
      " Avg loss: 0.000294 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.031414 [    0/10000]\n",
      "loss: 0.010629 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, 99.5%, 99.4%\n",
      " Avg loss: 0.000291 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.031123 [    0/10000]\n",
      "loss: 0.010560 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, 99.5%, 99.4%\n",
      " Avg loss: 0.000288 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.030838 [    0/10000]\n",
      "loss: 0.010492 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, 99.5%, 99.4%\n",
      " Avg loss: 0.000285 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.030564 [    0/10000]\n",
      "loss: 0.010425 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, 99.5%, 99.5%\n",
      " Avg loss: 0.000283 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.030298 [    0/10000]\n",
      "loss: 0.010360 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, 99.5%, 99.5%\n",
      " Avg loss: 0.000280 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.030040 [    0/10000]\n",
      "loss: 0.010296 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, 99.5%, 99.5%\n",
      " Avg loss: 0.000278 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.029790 [    0/10000]\n",
      "loss: 0.010233 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, 99.5%, 99.6%\n",
      " Avg loss: 0.000276 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.029548 [    0/10000]\n",
      "loss: 0.010172 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, 99.5%, 99.6%\n",
      " Avg loss: 0.000274 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.029313 [    0/10000]\n",
      "loss: 0.010113 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, 99.5%, 99.6%\n",
      " Avg loss: 0.000271 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.029085 [    0/10000]\n",
      "loss: 0.010054 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, 99.5%, 99.6%\n",
      " Avg loss: 0.000269 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.028864 [    0/10000]\n",
      "loss: 0.009997 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, 99.5%, 99.6%\n",
      " Avg loss: 0.000267 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.028649 [    0/10000]\n",
      "loss: 0.009941 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, 99.5%, 99.6%\n",
      " Avg loss: 0.000265 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.028441 [    0/10000]\n",
      "loss: 0.009886 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, 99.5%, 99.6%\n",
      " Avg loss: 0.000264 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.028233 [    0/10000]\n",
      "loss: 0.009832 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, 99.5%, 99.6%\n",
      " Avg loss: 0.000262 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.028037 [    0/10000]\n",
      "loss: 0.009779 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, 99.5%, 99.6%\n",
      " Avg loss: 0.000260 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.027847 [    0/10000]\n",
      "loss: 0.009724 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, 99.6%, 99.7%\n",
      " Avg loss: 0.000258 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.027661 [    0/10000]\n",
      "loss: 0.009673 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000257 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.027480 [    0/10000]\n",
      "loss: 0.009623 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000255 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.027302 [    0/10000]\n",
      "loss: 0.009573 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000254 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.027129 [    0/10000]\n",
      "loss: 0.009525 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000252 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.026959 [    0/10000]\n",
      "loss: 0.009476 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000251 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.026793 [    0/10000]\n",
      "loss: 0.009429 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000249 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.026631 [    0/10000]\n",
      "loss: 0.009382 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000248 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.026471 [    0/10000]\n",
      "loss: 0.009336 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000247 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.026315 [    0/10000]\n",
      "loss: 0.009290 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000245 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.026161 [    0/10000]\n",
      "loss: 0.009244 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000244 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.026009 [    0/10000]\n",
      "loss: 0.009199 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000243 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.025861 [    0/10000]\n",
      "loss: 0.009152 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000242 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.025718 [    0/10000]\n",
      "loss: 0.009108 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000240 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.025575 [    0/10000]\n",
      "loss: 0.009065 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000239 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.025433 [    0/10000]\n",
      "loss: 0.009022 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000238 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.025292 [    0/10000]\n",
      "loss: 0.008979 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000237 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.025151 [    0/10000]\n",
      "loss: 0.008937 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000236 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.025014 [    0/10000]\n",
      "loss: 0.008895 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000235 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.024878 [    0/10000]\n",
      "loss: 0.008853 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000234 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.024742 [    0/10000]\n",
      "loss: 0.008811 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000233 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.024609 [    0/10000]\n",
      "loss: 0.008770 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.8%\n",
      " Avg loss: 0.000232 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.024476 [    0/10000]\n",
      "loss: 0.008728 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000231 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.024345 [    0/10000]\n",
      "loss: 0.008687 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000230 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.024214 [    0/10000]\n",
      "loss: 0.008646 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000229 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.024085 [    0/10000]\n",
      "loss: 0.008606 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000228 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.023955 [    0/10000]\n",
      "loss: 0.008565 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000227 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.023828 [    0/10000]\n",
      "loss: 0.008524 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000226 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.023700 [    0/10000]\n",
      "loss: 0.008484 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000225 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.023573 [    0/10000]\n",
      "loss: 0.008443 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000224 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.023448 [    0/10000]\n",
      "loss: 0.008403 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000223 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.023322 [    0/10000]\n",
      "loss: 0.008363 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000222 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.023196 [    0/10000]\n",
      "loss: 0.008323 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000221 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.023072 [    0/10000]\n",
      "loss: 0.008282 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000220 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.022948 [    0/10000]\n",
      "loss: 0.008240 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000219 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.022831 [    0/10000]\n",
      "loss: 0.008200 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000218 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.022711 [    0/10000]\n",
      "loss: 0.008160 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000218 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.022589 [    0/10000]\n",
      "loss: 0.008121 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000217 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.022466 [    0/10000]\n",
      "loss: 0.008081 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000216 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.022344 [    0/10000]\n",
      "loss: 0.008041 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000215 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.022222 [    0/10000]\n",
      "loss: 0.007935 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000214 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.022168 [    0/10000]\n",
      "loss: 0.007890 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000214 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.022063 [    0/10000]\n",
      "loss: 0.007846 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000213 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.021951 [    0/10000]\n",
      "loss: 0.007799 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000212 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.021816 [    0/10000]\n",
      "loss: 0.007755 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.9%\n",
      " Avg loss: 0.000211 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.021688 [    0/10000]\n",
      "loss: 0.007711 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.9%\n",
      " Avg loss: 0.000210 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.021562 [    0/10000]\n",
      "loss: 0.007669 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.9%\n",
      " Avg loss: 0.000209 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.021438 [    0/10000]\n",
      "loss: 0.007627 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.9%\n",
      " Avg loss: 0.000209 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.021317 [    0/10000]\n",
      "loss: 0.007585 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.9%\n",
      " Avg loss: 0.000208 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.021197 [    0/10000]\n",
      "loss: 0.007543 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.9%\n",
      " Avg loss: 0.000207 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.021077 [    0/10000]\n",
      "loss: 0.007503 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.9%\n",
      " Avg loss: 0.000206 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.020959 [    0/10000]\n",
      "loss: 0.007462 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.9%\n",
      " Avg loss: 0.000206 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.020842 [    0/10000]\n",
      "loss: 0.007421 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.9%\n",
      " Avg loss: 0.000205 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.020724 [    0/10000]\n",
      "loss: 0.007380 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.9%\n",
      " Avg loss: 0.000204 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.020607 [    0/10000]\n",
      "loss: 0.007339 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.9%\n",
      " Avg loss: 0.000204 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.020491 [    0/10000]\n",
      "loss: 0.007298 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.9%\n",
      " Avg loss: 0.000203 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.020374 [    0/10000]\n",
      "loss: 0.007257 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.9%\n",
      " Avg loss: 0.000202 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.020258 [    0/10000]\n",
      "loss: 0.007214 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000201 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.020143 [    0/10000]\n",
      "loss: 0.007173 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000201 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.020028 [    0/10000]\n",
      "loss: 0.007132 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000200 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.019981 [    0/10000]\n",
      "loss: 0.007091 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000200 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.019870 [    0/10000]\n",
      "loss: 0.007050 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000199 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.019756 [    0/10000]\n",
      "loss: 0.007009 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000198 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.019642 [    0/10000]\n",
      "loss: 0.006969 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000198 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.019527 [    0/10000]\n",
      "loss: 0.006927 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000197 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.019413 [    0/10000]\n",
      "loss: 0.006886 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000196 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.019299 [    0/10000]\n",
      "loss: 0.006845 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000196 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.019185 [    0/10000]\n",
      "loss: 0.006803 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000195 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.019072 [    0/10000]\n",
      "loss: 0.006762 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000194 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.018958 [    0/10000]\n",
      "loss: 0.006720 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000194 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.018846 [    0/10000]\n",
      "loss: 0.006679 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000195 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.018961 [    0/10000]\n",
      "loss: 0.006631 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000194 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.018832 [    0/10000]\n",
      "loss: 0.006587 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000193 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.018733 [    0/10000]\n",
      "loss: 0.006542 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000193 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.018627 [    0/10000]\n",
      "loss: 0.006499 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000192 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.018519 [    0/10000]\n",
      "loss: 0.006457 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000192 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.018410 [    0/10000]\n",
      "loss: 0.006415 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000191 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.018302 [    0/10000]\n",
      "loss: 0.006373 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000190 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.018187 [    0/10000]\n",
      "loss: 0.006317 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000190 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.018086 [    0/10000]\n",
      "loss: 0.006274 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000189 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.017979 [    0/10000]\n",
      "loss: 0.006232 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.7%\n",
      " Avg loss: 0.000189 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.017872 [    0/10000]\n",
      "loss: 0.006190 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000188 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.017765 [    0/10000]\n",
      "loss: 0.006148 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000188 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.017658 [    0/10000]\n",
      "loss: 0.006106 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000187 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.017551 [    0/10000]\n",
      "loss: 0.006066 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000186 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.017445 [    0/10000]\n",
      "loss: 0.006024 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000186 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.017339 [    0/10000]\n",
      "loss: 0.005982 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000185 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.017233 [    0/10000]\n",
      "loss: 0.005941 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000185 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.017126 [    0/10000]\n",
      "loss: 0.005899 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000184 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.017020 [    0/10000]\n",
      "loss: 0.005857 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000184 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.016913 [    0/10000]\n",
      "loss: 0.005815 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000183 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.016797 [    0/10000]\n",
      "loss: 0.005781 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000182 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.016698 [    0/10000]\n",
      "loss: 0.005741 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000182 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.016598 [    0/10000]\n",
      "loss: 0.005699 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000181 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.016493 [    0/10000]\n",
      "loss: 0.005658 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000181 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.016386 [    0/10000]\n",
      "loss: 0.005616 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000180 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.016279 [    0/10000]\n",
      "loss: 0.005575 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000180 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.016172 [    0/10000]\n",
      "loss: 0.005537 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000180 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.016066 [    0/10000]\n",
      "loss: 0.005497 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000179 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.015959 [    0/10000]\n",
      "loss: 0.005456 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000179 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.015853 [    0/10000]\n",
      "loss: 0.005415 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000178 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.015747 [    0/10000]\n",
      "loss: 0.005374 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.8%\n",
      " Avg loss: 0.000178 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.015641 [    0/10000]\n",
      "loss: 0.005333 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000177 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.015535 [    0/10000]\n",
      "loss: 0.005293 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000177 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.015430 [    0/10000]\n",
      "loss: 0.005253 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000176 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.015325 [    0/10000]\n",
      "loss: 0.005213 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000176 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.015220 [    0/10000]\n",
      "loss: 0.005173 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000175 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.015115 [    0/10000]\n",
      "loss: 0.005133 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000175 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.015011 [    0/10000]\n",
      "loss: 0.005094 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000174 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.014907 [    0/10000]\n",
      "loss: 0.005054 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000174 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.014803 [    0/10000]\n",
      "loss: 0.005015 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000174 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.014699 [    0/10000]\n",
      "loss: 0.004976 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000173 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.014595 [    0/10000]\n",
      "loss: 0.004938 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000173 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.014492 [    0/10000]\n",
      "loss: 0.004899 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000172 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.014389 [    0/10000]\n",
      "loss: 0.004861 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000172 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.014286 [    0/10000]\n",
      "loss: 0.004823 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000171 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.014183 [    0/10000]\n",
      "loss: 0.004786 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000171 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.014080 [    0/10000]\n",
      "loss: 0.004748 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000171 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.013978 [    0/10000]\n",
      "loss: 0.004711 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000170 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.013876 [    0/10000]\n",
      "loss: 0.004675 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000170 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.013774 [    0/10000]\n",
      "loss: 0.004638 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000170 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.013672 [    0/10000]\n",
      "loss: 0.004602 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000169 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.013571 [    0/10000]\n",
      "loss: 0.004566 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000169 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.013470 [    0/10000]\n",
      "loss: 0.004531 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000168 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.013370 [    0/10000]\n",
      "loss: 0.004494 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000168 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.013273 [    0/10000]\n",
      "loss: 0.004459 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000168 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.013173 [    0/10000]\n",
      "loss: 0.004424 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000167 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.013073 [    0/10000]\n",
      "loss: 0.004390 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000167 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.012973 [    0/10000]\n",
      "loss: 0.004356 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000167 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.012874 [    0/10000]\n",
      "loss: 0.004322 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000166 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.012775 [    0/10000]\n",
      "loss: 0.004289 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000166 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.012677 [    0/10000]\n",
      "loss: 0.004256 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000166 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.012578 [    0/10000]\n",
      "loss: 0.004221 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000166 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.012479 [    0/10000]\n",
      "loss: 0.004189 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000165 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.012379 [    0/10000]\n",
      "loss: 0.004157 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000165 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.012282 [    0/10000]\n",
      "loss: 0.004125 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000165 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.012185 [    0/10000]\n",
      "loss: 0.004093 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000164 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.012089 [    0/10000]\n",
      "loss: 0.004062 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000164 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.011993 [    0/10000]\n",
      "loss: 0.004024 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000164 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.011915 [    0/10000]\n",
      "loss: 0.003994 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000164 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.011801 [    0/10000]\n",
      "loss: 0.003964 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000163 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.011704 [    0/10000]\n",
      "loss: 0.003934 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000163 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.011608 [    0/10000]\n",
      "loss: 0.003902 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000163 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.011514 [    0/10000]\n",
      "loss: 0.003873 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, 99.8%, 99.8%\n",
      " Avg loss: 0.000163 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.011420 [    0/10000]\n",
      "loss: 0.003845 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000163 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.011328 [    0/10000]\n",
      "loss: 0.003816 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000162 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.011236 [    0/10000]\n",
      "loss: 0.003788 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000163 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.011094 [    0/10000]\n",
      "loss: 0.003761 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000163 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.011004 [    0/10000]\n",
      "loss: 0.003733 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000162 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.010914 [    0/10000]\n",
      "loss: 0.003706 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000162 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.010824 [    0/10000]\n",
      "loss: 0.003680 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000162 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.010734 [    0/10000]\n",
      "loss: 0.003653 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000162 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.010645 [    0/10000]\n",
      "loss: 0.003627 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000162 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.010556 [    0/10000]\n",
      "loss: 0.003602 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000162 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.010468 [    0/10000]\n",
      "loss: 0.003576 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000161 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.010380 [    0/10000]\n",
      "loss: 0.003551 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000161 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.010293 [    0/10000]\n",
      "loss: 0.003526 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000161 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.010207 [    0/10000]\n",
      "loss: 0.003502 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000161 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.010120 [    0/10000]\n",
      "loss: 0.003478 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000161 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.010035 [    0/10000]\n",
      "loss: 0.003454 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000161 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.009950 [    0/10000]\n",
      "loss: 0.003430 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000161 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.009865 [    0/10000]\n",
      "loss: 0.003407 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.009781 [    0/10000]\n",
      "loss: 0.003384 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.009697 [    0/10000]\n",
      "loss: 0.003361 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.009615 [    0/10000]\n",
      "loss: 0.003338 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.009532 [    0/10000]\n",
      "loss: 0.003316 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.009451 [    0/10000]\n",
      "loss: 0.003294 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.009370 [    0/10000]\n",
      "loss: 0.003273 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.009290 [    0/10000]\n",
      "loss: 0.003251 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.009210 [    0/10000]\n",
      "loss: 0.003230 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.009131 [    0/10000]\n",
      "loss: 0.003209 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.009053 [    0/10000]\n",
      "loss: 0.003189 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.008975 [    0/10000]\n",
      "loss: 0.003169 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.008898 [    0/10000]\n",
      "loss: 0.003149 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.008822 [    0/10000]\n",
      "loss: 0.003129 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.008740 [    0/10000]\n",
      "loss: 0.003110 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000159 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.008665 [    0/10000]\n",
      "loss: 0.003090 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000159 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.008591 [    0/10000]\n",
      "loss: 0.003071 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000159 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.008517 [    0/10000]\n",
      "loss: 0.003053 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000159 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.008444 [    0/10000]\n",
      "loss: 0.003034 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000159 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.008372 [    0/10000]\n",
      "loss: 0.003016 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000159 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.008300 [    0/10000]\n",
      "loss: 0.002998 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000159 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.008230 [    0/10000]\n",
      "loss: 0.002980 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000159 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.008160 [    0/10000]\n",
      "loss: 0.002963 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000159 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.008090 [    0/10000]\n",
      "loss: 0.002946 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000159 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.008022 [    0/10000]\n",
      "loss: 0.002929 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000159 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.007954 [    0/10000]\n",
      "loss: 0.002901 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000159 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.007898 [    0/10000]\n",
      "loss: 0.002886 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000159 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.007833 [    0/10000]\n",
      "loss: 0.002871 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.007770 [    0/10000]\n",
      "loss: 0.002856 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.007707 [    0/10000]\n",
      "loss: 0.002840 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.007645 [    0/10000]\n",
      "loss: 0.002824 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.007582 [    0/10000]\n",
      "loss: 0.002809 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.007521 [    0/10000]\n",
      "loss: 0.002794 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.007460 [    0/10000]\n",
      "loss: 0.002779 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.007400 [    0/10000]\n",
      "loss: 0.002764 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.007341 [    0/10000]\n",
      "loss: 0.002750 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.007282 [    0/10000]\n",
      "loss: 0.002735 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.007223 [    0/10000]\n",
      "loss: 0.002721 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.007166 [    0/10000]\n",
      "loss: 0.002707 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.007109 [    0/10000]\n",
      "loss: 0.002695 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.007055 [    0/10000]\n",
      "loss: 0.002678 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.007004 [    0/10000]\n",
      "loss: 0.002665 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.006950 [    0/10000]\n",
      "loss: 0.002649 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.006891 [    0/10000]\n",
      "loss: 0.002636 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000161 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.006837 [    0/10000]\n",
      "loss: 0.002623 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000161 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.006783 [    0/10000]\n",
      "loss: 0.002611 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000161 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.006731 [    0/10000]\n",
      "loss: 0.002599 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000161 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.006680 [    0/10000]\n",
      "loss: 0.002587 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000161 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.006630 [    0/10000]\n",
      "loss: 0.002575 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000161 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.006580 [    0/10000]\n",
      "loss: 0.002563 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000161 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.006532 [    0/10000]\n",
      "loss: 0.002552 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000161 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.006484 [    0/10000]\n",
      "loss: 0.002540 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000161 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.006436 [    0/10000]\n",
      "loss: 0.002529 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000161 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.006390 [    0/10000]\n",
      "loss: 0.002518 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000162 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.006345 [    0/10000]\n",
      "loss: 0.002507 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000162 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.006300 [    0/10000]\n",
      "loss: 0.002489 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000161 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.006239 [    0/10000]\n",
      "loss: 0.002477 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000162 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.006193 [    0/10000]\n",
      "loss: 0.002469 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000162 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.006148 [    0/10000]\n",
      "loss: 0.002460 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000162 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.006105 [    0/10000]\n",
      "loss: 0.002451 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000162 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.006063 [    0/10000]\n",
      "loss: 0.002442 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000162 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.006021 [    0/10000]\n",
      "loss: 0.002432 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000162 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.005981 [    0/10000]\n",
      "loss: 0.002423 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000162 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.005941 [    0/10000]\n",
      "loss: 0.002414 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000163 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.005904 [    0/10000]\n",
      "loss: 0.002404 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000163 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.005866 [    0/10000]\n",
      "loss: 0.002395 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000163 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.005828 [    0/10000]\n",
      "loss: 0.002386 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000163 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.005791 [    0/10000]\n",
      "loss: 0.002376 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000163 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.005755 [    0/10000]\n",
      "loss: 0.002367 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000163 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.005719 [    0/10000]\n",
      "loss: 0.002358 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000163 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.005684 [    0/10000]\n",
      "loss: 0.002349 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000164 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.005650 [    0/10000]\n",
      "loss: 0.002340 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000164 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.005617 [    0/10000]\n",
      "loss: 0.002331 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000164 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.005584 [    0/10000]\n",
      "loss: 0.002322 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000164 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.005552 [    0/10000]\n",
      "loss: 0.002313 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000164 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.005521 [    0/10000]\n",
      "loss: 0.002304 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000164 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.005490 [    0/10000]\n",
      "loss: 0.002295 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000165 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.005459 [    0/10000]\n",
      "loss: 0.002286 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000165 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.005430 [    0/10000]\n",
      "loss: 0.002278 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000165 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.005401 [    0/10000]\n",
      "loss: 0.002269 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000165 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.005373 [    0/10000]\n",
      "loss: 0.002261 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000165 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.005345 [    0/10000]\n",
      "loss: 0.002252 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000165 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.005318 [    0/10000]\n",
      "loss: 0.002244 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000166 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.005292 [    0/10000]\n",
      "loss: 0.002236 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000166 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.005266 [    0/10000]\n",
      "loss: 0.002228 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000166 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.005240 [    0/10000]\n",
      "loss: 0.002220 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000166 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.005216 [    0/10000]\n",
      "loss: 0.002228 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000166 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.005176 [    0/10000]\n",
      "loss: 0.002201 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000166 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.005140 [    0/10000]\n",
      "loss: 0.002191 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000166 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.005113 [    0/10000]\n",
      "loss: 0.002183 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000144 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.006291 [    0/10000]\n",
      "loss: 0.002132 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000168 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.005033 [    0/10000]\n",
      "loss: 0.002170 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000169 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.005016 [    0/10000]\n",
      "loss: 0.002165 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000146 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.006199 [    0/10000]\n",
      "loss: 0.002114 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000169 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.004947 [    0/10000]\n",
      "loss: 0.002150 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000147 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.006141 [    0/10000]\n",
      "loss: 0.002101 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000171 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.004883 [    0/10000]\n",
      "loss: 0.002139 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000148 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.006066 [    0/10000]\n",
      "loss: 0.002089 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000172 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.004831 [    0/10000]\n",
      "loss: 0.002128 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000149 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.005988 [    0/10000]\n",
      "loss: 0.002077 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000149 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.005958 [    0/10000]\n",
      "loss: 0.002095 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000175 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.004758 [    0/10000]\n",
      "loss: 0.002117 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000151 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.005881 [    0/10000]\n",
      "loss: 0.002060 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000150 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.005842 [    0/10000]\n",
      "loss: 0.002054 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000151 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.005826 [    0/10000]\n",
      "loss: 0.002074 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000153 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.005808 [    0/10000]\n",
      "loss: 0.002069 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000154 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.005776 [    0/10000]\n",
      "loss: 0.002064 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000154 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.005735 [    0/10000]\n",
      "loss: 0.002060 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000155 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.005691 [    0/10000]\n",
      "loss: 0.002056 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000156 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.005648 [    0/10000]\n",
      "loss: 0.002054 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000157 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.005604 [    0/10000]\n",
      "loss: 0.002052 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000157 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.005560 [    0/10000]\n",
      "loss: 0.002050 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000158 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.005516 [    0/10000]\n",
      "loss: 0.002013 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000158 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.005446 [    0/10000]\n",
      "loss: 0.002016 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000159 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.005413 [    0/10000]\n",
      "loss: 0.002009 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000160 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.005357 [    0/10000]\n",
      "loss: 0.002008 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000161 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.005316 [    0/10000]\n",
      "loss: 0.002009 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000162 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.005278 [    0/10000]\n",
      "loss: 0.002009 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000163 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.005241 [    0/10000]\n",
      "loss: 0.002010 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000164 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.005204 [    0/10000]\n",
      "loss: 0.002011 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000165 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.005169 [    0/10000]\n",
      "loss: 0.002011 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000166 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.005136 [    0/10000]\n",
      "loss: 0.002014 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000167 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.005102 [    0/10000]\n",
      "loss: 0.002018 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000168 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.005069 [    0/10000]\n",
      "loss: 0.002021 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000169 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.005037 [    0/10000]\n",
      "loss: 0.002026 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000170 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.005006 [    0/10000]\n",
      "loss: 0.002031 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000171 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.004976 [    0/10000]\n",
      "loss: 0.002037 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000172 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.004946 [    0/10000]\n",
      "loss: 0.002044 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000173 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.004918 [    0/10000]\n",
      "loss: 0.002051 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000174 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.004891 [    0/10000]\n",
      "loss: 0.002059 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000176 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.004865 [    0/10000]\n",
      "loss: 0.002067 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000177 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.004841 [    0/10000]\n",
      "loss: 0.002077 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000178 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.004818 [    0/10000]\n",
      "loss: 0.002086 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000179 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.004797 [    0/10000]\n",
      "loss: 0.002097 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000180 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.004776 [    0/10000]\n",
      "loss: 0.002108 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000181 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.004756 [    0/10000]\n",
      "loss: 0.002121 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000182 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.004737 [    0/10000]\n",
      "loss: 0.002133 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000183 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.004720 [    0/10000]\n",
      "loss: 0.002147 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000184 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.004703 [    0/10000]\n",
      "loss: 0.002162 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000185 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.004688 [    0/10000]\n",
      "loss: 0.002177 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000186 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.004674 [    0/10000]\n",
      "loss: 0.002193 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000187 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.004660 [    0/10000]\n",
      "loss: 0.002209 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000188 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.004648 [    0/10000]\n",
      "loss: 0.002227 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000189 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.004636 [    0/10000]\n",
      "loss: 0.002241 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000190 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.004631 [    0/10000]\n",
      "loss: 0.002260 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000191 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.004620 [    0/10000]\n",
      "loss: 0.002280 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000191 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.004611 [    0/10000]\n",
      "loss: 0.002301 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000192 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.004602 [    0/10000]\n",
      "loss: 0.002323 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000193 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.004594 [    0/10000]\n",
      "loss: 0.002346 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000194 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.004587 [    0/10000]\n",
      "loss: 0.002370 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000195 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.004580 [    0/10000]\n",
      "loss: 0.002395 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000196 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.004574 [    0/10000]\n",
      "loss: 0.002420 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000197 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.004569 [    0/10000]\n",
      "loss: 0.002447 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000197 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.004564 [    0/10000]\n",
      "loss: 0.002475 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.8%, 99.7%\n",
      " Avg loss: 0.000198 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.004559 [    0/10000]\n",
      "loss: 0.002504 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000199 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.004554 [    0/10000]\n",
      "loss: 0.002534 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000200 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.004550 [    0/10000]\n",
      "loss: 0.002565 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000200 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.004546 [    0/10000]\n",
      "loss: 0.002597 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000201 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.004543 [    0/10000]\n",
      "loss: 0.002631 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000202 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.004540 [    0/10000]\n",
      "loss: 0.002697 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000202 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.004556 [    0/10000]\n",
      "loss: 0.002735 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000203 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.004556 [    0/10000]\n",
      "loss: 0.002775 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000204 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.004554 [    0/10000]\n",
      "loss: 0.002817 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.7%, 99.6%\n",
      " Avg loss: 0.000204 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.004552 [    0/10000]\n",
      "loss: 0.002859 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000205 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.004550 [    0/10000]\n",
      "loss: 0.002903 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000205 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.004548 [    0/10000]\n",
      "loss: 0.002947 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000206 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.004547 [    0/10000]\n",
      "loss: 0.002995 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000207 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.004546 [    0/10000]\n",
      "loss: 0.003042 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000207 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.004546 [    0/10000]\n",
      "loss: 0.003070 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000208 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.004543 [    0/10000]\n",
      "loss: 0.003122 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000208 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.004545 [    0/10000]\n",
      "loss: 0.003173 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000210 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.004522 [    0/10000]\n",
      "loss: 0.003281 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000211 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.004533 [    0/10000]\n",
      "loss: 0.003354 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000211 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.004550 [    0/10000]\n",
      "loss: 0.003417 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000211 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.004560 [    0/10000]\n",
      "loss: 0.003479 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000212 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.004570 [    0/10000]\n",
      "loss: 0.003539 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000212 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.004581 [    0/10000]\n",
      "loss: 0.003597 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000212 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.004591 [    0/10000]\n",
      "loss: 0.003653 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000213 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.004600 [    0/10000]\n",
      "loss: 0.003708 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000213 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.004610 [    0/10000]\n",
      "loss: 0.003762 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000213 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.004618 [    0/10000]\n",
      "loss: 0.003814 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000213 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.004626 [    0/10000]\n",
      "loss: 0.003866 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000214 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.004633 [    0/10000]\n",
      "loss: 0.003976 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000214 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.004789 [    0/10000]\n",
      "loss: 0.003964 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000214 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.004784 [    0/10000]\n",
      "loss: 0.004010 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000213 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.004843 [    0/10000]\n",
      "loss: 0.004024 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000213 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.004820 [    0/10000]\n",
      "loss: 0.004034 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000213 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.004786 [    0/10000]\n",
      "loss: 0.004081 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000214 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.004771 [    0/10000]\n",
      "loss: 0.004129 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000214 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.004759 [    0/10000]\n",
      "loss: 0.004177 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000215 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.004745 [    0/10000]\n",
      "loss: 0.004225 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000215 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.004729 [    0/10000]\n",
      "loss: 0.004273 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000215 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.004709 [    0/10000]\n",
      "loss: 0.004321 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000216 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.004684 [    0/10000]\n",
      "loss: 0.004365 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000215 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.004658 [    0/10000]\n",
      "loss: 0.004357 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000215 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.004642 [    0/10000]\n",
      "loss: 0.004384 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000216 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.004618 [    0/10000]\n",
      "loss: 0.004421 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000216 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.004589 [    0/10000]\n",
      "loss: 0.004462 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000217 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.004555 [    0/10000]\n",
      "loss: 0.004504 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000217 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.004516 [    0/10000]\n",
      "loss: 0.004547 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000218 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.004472 [    0/10000]\n",
      "loss: 0.004590 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000219 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.004424 [    0/10000]\n",
      "loss: 0.004632 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000219 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.004371 [    0/10000]\n",
      "loss: 0.004673 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000220 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.004314 [    0/10000]\n",
      "loss: 0.004710 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000221 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.004257 [    0/10000]\n",
      "loss: 0.004744 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000222 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.004199 [    0/10000]\n",
      "loss: 0.004771 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000222 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.004144 [    0/10000]\n",
      "loss: 0.004843 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000217 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.004420 [    0/10000]\n",
      "loss: 0.004561 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000220 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.004115 [    0/10000]\n",
      "loss: 0.004788 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000217 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.004355 [    0/10000]\n",
      "loss: 0.004602 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000221 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.004018 [    0/10000]\n",
      "loss: 0.004858 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000218 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.004259 [    0/10000]\n",
      "loss: 0.004649 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000222 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.003926 [    0/10000]\n",
      "loss: 0.004956 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000219 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.004164 [    0/10000]\n",
      "loss: 0.004655 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000223 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.003859 [    0/10000]\n",
      "loss: 0.004937 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000219 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.004103 [    0/10000]\n",
      "loss: 0.004607 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000216 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.004161 [    0/10000]\n",
      "loss: 0.004546 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000223 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.003770 [    0/10000]\n",
      "loss: 0.004969 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000220 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.003965 [    0/10000]\n",
      "loss: 0.004637 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000217 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.004040 [    0/10000]\n",
      "loss: 0.004545 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000216 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.004007 [    0/10000]\n",
      "loss: 0.004580 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000217 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.003944 [    0/10000]\n",
      "loss: 0.004644 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000218 \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.003882 [    0/10000]\n",
      "loss: 0.004692 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000219 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.003828 [    0/10000]\n",
      "loss: 0.004714 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000219 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.003785 [    0/10000]\n",
      "loss: 0.004715 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000220 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.003750 [    0/10000]\n",
      "loss: 0.004701 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000220 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.003719 [    0/10000]\n",
      "loss: 0.004678 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000220 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.003691 [    0/10000]\n",
      "loss: 0.004651 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000220 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.003665 [    0/10000]\n",
      "loss: 0.004622 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000221 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.003639 [    0/10000]\n",
      "loss: 0.004590 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000221 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.003614 [    0/10000]\n",
      "loss: 0.004558 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.7%, 99.5%\n",
      " Avg loss: 0.000221 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.003589 [    0/10000]\n",
      "loss: 0.004524 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.4%\n",
      " Avg loss: 0.000221 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.003565 [    0/10000]\n",
      "loss: 0.004489 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.4%\n",
      " Avg loss: 0.000221 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.003541 [    0/10000]\n",
      "loss: 0.004452 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.4%\n",
      " Avg loss: 0.000222 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.003518 [    0/10000]\n",
      "loss: 0.004416 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.4%\n",
      " Avg loss: 0.000222 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.003495 [    0/10000]\n",
      "loss: 0.004378 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.4%\n",
      " Avg loss: 0.000222 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.003472 [    0/10000]\n",
      "loss: 0.004340 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.4%\n",
      " Avg loss: 0.000222 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.003449 [    0/10000]\n",
      "loss: 0.004302 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.4%\n",
      " Avg loss: 0.000222 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.003427 [    0/10000]\n",
      "loss: 0.004264 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.4%\n",
      " Avg loss: 0.000222 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.003405 [    0/10000]\n",
      "loss: 0.004224 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.4%\n",
      " Avg loss: 0.000222 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.003382 [    0/10000]\n",
      "loss: 0.004186 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.4%\n",
      " Avg loss: 0.000222 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.003360 [    0/10000]\n",
      "loss: 0.004148 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.6%, 99.5%\n",
      " Avg loss: 0.000223 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.003338 [    0/10000]\n",
      "loss: 0.004110 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.6%, 99.5%\n",
      " Avg loss: 0.000223 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.003316 [    0/10000]\n",
      "loss: 0.004071 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.6%, 99.5%\n",
      " Avg loss: 0.000223 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.003294 [    0/10000]\n",
      "loss: 0.004033 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.6%, 99.5%\n",
      " Avg loss: 0.000223 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.003272 [    0/10000]\n",
      "loss: 0.003994 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.6%, 99.5%\n",
      " Avg loss: 0.000223 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.003251 [    0/10000]\n",
      "loss: 0.003956 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.6%, 99.5%\n",
      " Avg loss: 0.000223 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.003229 [    0/10000]\n",
      "loss: 0.003917 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.6%, 99.5%\n",
      " Avg loss: 0.000231 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.003087 [    0/10000]\n",
      "loss: 0.004188 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, 99.6%, 99.4%\n",
      " Avg loss: 0.000227 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.003145 [    0/10000]\n",
      "loss: 0.003607 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.6%, 99.5%\n",
      " Avg loss: 0.000229 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.003173 [    0/10000]\n",
      "loss: 0.003726 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.6%, 99.5%\n",
      " Avg loss: 0.000223 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.003221 [    0/10000]\n",
      "loss: 0.003417 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.6%, 99.5%\n",
      " Avg loss: 0.000229 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.003127 [    0/10000]\n",
      "loss: 0.003778 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.6%, 99.5%\n",
      " Avg loss: 0.000225 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.003139 [    0/10000]\n",
      "loss: 0.003376 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.6%, 99.5%\n",
      " Avg loss: 0.000229 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.003098 [    0/10000]\n",
      "loss: 0.003656 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.6%, 99.5%\n",
      " Avg loss: 0.000224 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.003123 [    0/10000]\n",
      "loss: 0.003249 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.6%, 99.5%\n",
      " Avg loss: 0.000229 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.003078 [    0/10000]\n",
      "loss: 0.003602 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.6%, 99.5%\n",
      " Avg loss: 0.000225 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.003082 [    0/10000]\n",
      "loss: 0.003165 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.6%, 99.5%\n",
      " Avg loss: 0.000229 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.003049 [    0/10000]\n",
      "loss: 0.003539 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.6%, 99.5%\n",
      " Avg loss: 0.000225 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.003044 [    0/10000]\n",
      "loss: 0.003078 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.6%, 99.5%\n",
      " Avg loss: 0.000229 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.003022 [    0/10000]\n",
      "loss: 0.003479 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, 99.6%, 99.5%\n",
      " Avg loss: 0.000225 \n",
      "\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment = Experiment('midcircle', model, shapes, constraints)\n",
    "experiment.run(500)\n",
    "experiment.save(dir='./models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
