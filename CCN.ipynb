{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle as RectPatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Rectangle:\n",
    "    def __init__(self, x0, x1, y0, y1):\n",
    "        self.lower = np.array([x0, y0])\n",
    "        self.higher = np.array([x1, y1])\n",
    "        \n",
    "    def inside(self, x, y):\n",
    "        point = np.array([x, y])\n",
    "        return ((self.lower <= point) * (point <= self.higher)).sum().item() == 2\n",
    "    \n",
    "    def plot(self, ax, edgecolor = 'blue'):\n",
    "        dim = self.higher - self.lower\n",
    "        ax.add_patch(RectPatch((self.lower[0], self.lower[1]), dim[0], dim[1], fill = False, edgecolor = edgecolor))\n",
    "    \n",
    "rect0 = Rectangle(0.1, 0.6, 0.1, 0.6)\n",
    "rect1 = Rectangle(0.4, 0.9, 0.4, 0.9)\n",
    "\n",
    "def draw_rectangles(ax, rect0, rect1):\n",
    "    plt.axis([0., 1., 0., 1.])\n",
    "    rect0.plot(ax, 'red')\n",
    "    rect1.plot(ax)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "draw_rectangles(ax, rect0, rect1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RectanglesDataset(Dataset):\n",
    "    def __init__(self, count, r0, r1):\n",
    "        super(RectanglesDataset, self).__init__()\n",
    "        self.r0 = r0\n",
    "        self.r1 = r1\n",
    "\n",
    "        self.values = [torch.rand((2,)) for i in range(count)]\n",
    "        self.labels = [self.correct(x, y) for (x, y) in self.values]\n",
    "\n",
    "    def correct(self, x, y):\n",
    "        small = self.r0.inside(x, y)\n",
    "        big = small or self.r1.inside(x, y)\n",
    "        return torch.tensor([1. if v else 0. for v in [small, big]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.values)  \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.values[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = 10000\n",
    "train_data = RectanglesDataset(points, rect0, rect1)\n",
    "test_data = RectanglesDataset(points // 10, rect0, rect1)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size = 64)\n",
    "test_dataloader = DataLoader(test_data, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=2, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(2, 4),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(4, 2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The CCN framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "n13\n",
      "n12\n",
      "12\n",
      "17\n",
      "n17\n",
      "n19\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "class Literal:\n",
    "    def __init__(self, *args):\n",
    "        if len(args) == 2:\n",
    "            # Literal(int, bool)\n",
    "            self.atom = args[0]\n",
    "            self.positive = args[1]\n",
    "        else:\n",
    "            # Literal(string)\n",
    "            plain = args[0]\n",
    "            if 'n' in plain:\n",
    "                self.atom = int(plain[1:])\n",
    "                self.positive = False\n",
    "            else:\n",
    "                self.atom = int(plain)\n",
    "                self.positive = True\n",
    "            \n",
    "    def neg(self):\n",
    "        return Literal(self.atom, not self.positive)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.atom) if self.positive else 'n' + str(self.atom)\n",
    "    \n",
    "for lit in [Literal('13'), Literal('n12'), Literal(17, True), Literal(19, False)]:\n",
    "    print(str(lit))\n",
    "    print(str(lit.neg()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :- 0\n",
      "0 :- 1 n2\n",
      "n0 :- n1 2 3\n"
     ]
    }
   ],
   "source": [
    "class Constraint:\n",
    "    def __init__(self, *args):\n",
    "        if len(args) == 2:\n",
    "            # Constraint(Literal, [Literal])\n",
    "            self.head = args[0]\n",
    "            self.body = args[1]\n",
    "        else:\n",
    "            # Constraint(string)\n",
    "            line = args[0].split(' ')\n",
    "            if line[2] == ':-':\n",
    "                line = line[1:]\n",
    "            assert line[1] == ':-'\n",
    "            self.head = Literal(line[0])\n",
    "            self.body = [Literal(lit) for lit in line[2:]]\n",
    "            \n",
    "    def head_encoded(self, num_classes):\n",
    "        pos_head = np.zeros(num_classes)\n",
    "        neg_head = np.zeros(num_classes)\n",
    "        if self.head.positive:\n",
    "            pos_head[self.head.atom] = 1\n",
    "        else:\n",
    "            neg_head[self.head.atom] = 1\n",
    "        return pos_head, neg_head\n",
    "    \n",
    "    def body_encoded(self, num_classes):\n",
    "        pos_body = np.zeros(num_classes, dtype=int)\n",
    "        neg_body = np.zeros(num_classes, dtype=int)\n",
    "        for lit in self.body:\n",
    "            if lit.positive:\n",
    "                pos_body[lit.atom] = 1\n",
    "            else:\n",
    "                neg_body[lit.atom] = 1\n",
    "        return pos_body, neg_body\n",
    "    \n",
    "    def where(self, cond, opt1, opt2):\n",
    "        return opt2 + cond * (opt1 - opt2)\n",
    "    \n",
    "    def coherent_with(self, preds):\n",
    "        num_classes = preds.shape[1]\n",
    "        pos_body, neg_body = self.body_encoded(num_classes)\n",
    "        pos_body = preds[:, pos_body.astype(bool)]\n",
    "        neg_body = 1 - preds[:, neg_body.astype(bool)]\n",
    "        body = np.min(np.concatenate((pos_body, neg_body), axis=1), axis=1)\n",
    "        \n",
    "        head = preds[:, self.head.atom]\n",
    "        if not self.head.positive:\n",
    "            head = 1 - head\n",
    "            \n",
    "        return body <= head\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.head) + \" :- \" + ' '.join([str(lit) for lit in self.body])\n",
    "    \n",
    "    \n",
    "cons0 = Constraint(Literal('1'), [Literal('0')])\n",
    "cons1 = Constraint('0 :- 1 n2')\n",
    "cons2 = Constraint('n0 :- n1 2 3')\n",
    "    \n",
    "for cons in [cons0, cons1, cons2]:\n",
    "    print(cons)\n",
    "\n",
    "assert (cons0.coherent_with(np.array([\n",
    "    [0.1, 0.2],\n",
    "    [0.2, 0.1],\n",
    "    [0.1, 0.1]\n",
    "])) == [True, False, True]).all()\n",
    "\n",
    "assert (cons2.coherent_with(np.array([\n",
    "    [0.7, 0.8, 0.3, 0.4],\n",
    "    [0.8, 0.8, 0.3, 0.4],\n",
    "    [0.9, 0.8, 0.3, 0.4],\n",
    "])) == [True, True, False]).all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :- 0\n",
      "0 :- 1 n2\n",
      "n0 :- n1 2 3\n"
     ]
    }
   ],
   "source": [
    "class ConstraintsGroup:\n",
    "    def __init__(self, arg):\n",
    "        if isinstance(arg, list):\n",
    "            # ConstraintGroup([Constraint])\n",
    "            self.constraints = arg\n",
    "        else:\n",
    "            # ConstraintGroup(string)\n",
    "            with open(arg, 'r') as f:\n",
    "                self.constraints = [Constraint(line) for line in f]\n",
    "                \n",
    "    def strata(self):\n",
    "        # TODO: Implement stratification\n",
    "        return [self, self]\n",
    "                \n",
    "    def head_encoded(self, num_classes):\n",
    "        pos_head = []\n",
    "        neg_head = []\n",
    "        \n",
    "        for constraint in self.constraints:\n",
    "            pos, neg = constraint.head_encoded(num_classes)\n",
    "            pos_head.append(pos)\n",
    "            neg_head.append(neg)\n",
    "            \n",
    "        return np.array(pos_head), np.array(neg_head)\n",
    "    \n",
    "    def body_encoded(self, num_classes):\n",
    "        pos_body = []\n",
    "        neg_body = []\n",
    "        \n",
    "        for constraint in self.constraints:\n",
    "            pos, neg = constraint.body_encoded(num_classes)\n",
    "            pos_body.append(pos)\n",
    "            neg_body.append(neg)\n",
    "            \n",
    "        return np.array(pos_body), np.array(neg_body)\n",
    "            \n",
    "    def encoded(self, num_classes):\n",
    "        head = self.head_encoded(num_classes)\n",
    "        body = self.body_encoded(num_classes)\n",
    "        return head, body\n",
    "    \n",
    "    def coherent_with(self, preds):\n",
    "        coherent = [constraint.coherent_with(preds) for constraint in self.constraints]\n",
    "        return np.array(coherent).transpose()\n",
    "            \n",
    "    def __str__(self):\n",
    "        return '\\n'.join([str(constraint) for constraint in self.constraints])\n",
    "        \n",
    "constraints_group = ConstraintsGroup([cons0, cons1, cons2])\n",
    "print(constraints_group)\n",
    "#print(ConstraintGroup('/Users/home/Desktop/PyToys/constraint'))\n",
    "\n",
    "assert (constraints_group.coherent_with(np.array([\n",
    "    [0.1, 0.2, 0.3, 0.4],\n",
    "    [0.7, 0.2, 0.3, 0.4],\n",
    "    [0.8, 0.2, 0.3, 0.4]\n",
    "])) == np.array([\n",
    "     [ True, False,  True],\n",
    "     [False,  True,  True],\n",
    "     [False,  True, False]])).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConstraintsModule()\n"
     ]
    }
   ],
   "source": [
    "class ConstraintsModule(nn.Module):\n",
    "    def __init__(self, constraints_group, num_classes):\n",
    "        super(ConstraintsModule, self).__init__()\n",
    "        head, body = constraints_group.encoded(num_classes)\n",
    "        pos_head, neg_head = head\n",
    "        pos_body, neg_body = body\n",
    "        \n",
    "        # TODO: Maybe combine pos/neg_head into head, same for body\n",
    "        # TODO: use +/-1 to signal positive negative, and transform [0, 1] -> [-1, 1]\n",
    "        self.pos_head = torch.from_numpy(pos_head).float()\n",
    "        self.neg_head = torch.from_numpy(neg_head).float()\n",
    "        self.pos_body = torch.from_numpy(pos_body).float()\n",
    "        self.neg_body = torch.from_numpy(neg_body).float()\n",
    "        \n",
    "    def where(self, cond, opt1, opt2):\n",
    "        return opt2 + cond * (opt1 - opt2)\n",
    "    \n",
    "    def dimensions(self, pred):\n",
    "        batch, num = pred.shape[0], pred.shape[1]\n",
    "        cons = self.pos_head.shape[0]\n",
    "        return batch, num, cons\n",
    "    \n",
    "    # Get the constraints whose body (& head) is satisfied by goal\n",
    "    def satisfied_body_constraints(self, goal):\n",
    "        batch, num, cons = self.dimensions(goal)\n",
    "        \n",
    "        # batch x cons: compute matching body\n",
    "        pos_matches = torch.matmul(goal, self.pos_body.t().float())\n",
    "        neg_matches = torch.matmul(1 - goal, self.neg_body.t().float())\n",
    "        matches = pos_matches + neg_matches\n",
    "        \n",
    "        # batch x cons: compute necessary matches\n",
    "        necessary = self.pos_body.sum(dim=1) + self.neg_body.sum(dim=1)\n",
    "        necessary = necessary.unsqueeze(0).expand(batch, cons)\n",
    "        \n",
    "        # batch x cons: compute satisfying constraints\n",
    "        return torch.where(matches == necessary, 1, 0)\n",
    "    \n",
    "    # Get the constraints whose head is not satisfied by goal\n",
    "    def unsatisfied_head_constraints(self, goal):\n",
    "        batch, num, cons = self.dimensions(goal)\n",
    "        \n",
    "        # batch x cons: compute constraints with pos heads\n",
    "        pos_cons = self.pos_head.sum(dim=1).unsqueeze(0).expand(batch, cons)\n",
    "        \n",
    "        # batch x cons: compute constraints with head unsatisfied\n",
    "        pos_head = (1 - torch.matmul(goal, self.pos_head.t())) * pos_cons\n",
    "        neg_head = torch.matmul(goal, self.neg_head.t())\n",
    "        \n",
    "        return pos_head + neg_head\n",
    "    \n",
    "    # Get the literals unsatisfied by goal\n",
    "    def unsatisfied_literals_mask(self, goal):\n",
    "        batch, num, cons = self.dimensions(goal)\n",
    "        \n",
    "        # batch x cons x num: compute (un)satisfied literals\n",
    "        goal = goal.unsqueeze(1).expand(batch, cons, num)\n",
    "        return 1 - goal, goal\n",
    "    \n",
    "    def apply(self, preds, active_constraints=None, body_mask=None):\n",
    "        batch, num, cons = self.dimensions(preds)\n",
    "        \n",
    "        # batch x cons x num: prepare (preds x body)\n",
    "        exp_preds = preds.unsqueeze(1).expand(batch, cons, num)\n",
    "        pos_body = self.pos_body.unsqueeze(0).expand(batch, cons, num)\n",
    "        neg_body = self.neg_body.unsqueeze(0).expand(batch, cons, num)\n",
    "        \n",
    "        # ignore literals from constraints\n",
    "        if body_mask != None:\n",
    "            pos_mask, neg_mask = body_mask\n",
    "            pos_body = pos_body * pos_mask \n",
    "            neg_body = neg_body * neg_mask\n",
    "        \n",
    "        # batch x cons: compute body minima\n",
    "        pos_body_min = torch.min(self.where(pos_body, exp_preds, 1), dim=2).values\n",
    "        neg_body_min = torch.min(self.where(neg_body, 1. - exp_preds, 1), dim=2).values\n",
    "        body_min = torch.minimum(pos_body_min, neg_body_min)\n",
    "        \n",
    "        # ignore constraints\n",
    "        if active_constraints != None:\n",
    "            body_min = body_min * active_constraints\n",
    "        \n",
    "        # batch x cons x num: prepare (body_min x head)\n",
    "        body_min = body_min.unsqueeze(2).expand(batch, cons, num)\n",
    "        pos_head = self.pos_head.unsqueeze(0).expand(batch, cons, num)\n",
    "        neg_head = self.neg_head.unsqueeze(0).expand(batch, cons, num)\n",
    "        \n",
    "        # batch x num: compute head lower and upper bounds\n",
    "        pos_head_max = torch.max(body_min * pos_head, dim=1).values.float()\n",
    "        neg_head_max = torch.max(body_min * neg_head, dim=1).values.float()\n",
    "        preds = torch.maximum(pos_head_max, torch.minimum(1 - neg_head_max, preds.squeeze()))\n",
    "        return preds\n",
    "        \n",
    "    def forward(self, preds, goal = None):\n",
    "        if goal == None:\n",
    "            return self.apply(preds)\n",
    "        \n",
    "        # constraints with head satisfied (only with full body satisfied)\n",
    "        active_constraints = self.satisfied_body_constraints(goal)\n",
    "        preds = self.apply(preds, active_constraints=active_constraints)\n",
    "        \n",
    "        # constraints with head not satisfied (only unsatisfied body literals)\n",
    "        active_constraints = self.unsatisfied_head_constraints(goal)\n",
    "        body_mask = self.unsatisfied_literals_mask(goal)\n",
    "        preds = self.apply(preds, active_constraints=active_constraints, body_mask=body_mask)\n",
    "        \n",
    "        return preds\n",
    "        \n",
    "        \n",
    "constraints_group = ConstraintsGroup([\n",
    "    Constraint('1 :- 0'),\n",
    "    Constraint('2 :- n3 4'),\n",
    "    Constraint('n5 :- 6 n7 8'),\n",
    "    Constraint('2 :- 9 n10'),\n",
    "    Constraint('n5 :- 11 n12 n13'),\n",
    "])\n",
    "\n",
    "cm = ConstraintsModule(constraints_group, 14)\n",
    "print(cm)\n",
    "preds = torch.rand((1000, 14))\n",
    "updated = cm(preds)\n",
    "assert constraints_group.coherent_with(updated.numpy()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConstraintsLayer(\n",
      "  (module_list): ModuleList(\n",
      "    (0): ConstraintsModule()\n",
      "    (1): ConstraintsModule()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ConstraintsLayer(nn.Module):\n",
    "    def __init__(self, constraints_group, num_classes):\n",
    "        super(ConstraintsLayer, self).__init__()\n",
    "        strata = constraints_group.strata()\n",
    "        modules = [ConstraintsModule(stratum, num_classes) for stratum in strata]\n",
    "        self.module_list = nn.ModuleList(modules)\n",
    "        \n",
    "    def forward(self, x, goal=None):\n",
    "        for module in self.module_list:\n",
    "            x = module(x, goal=goal)\n",
    "        return x\n",
    "    \n",
    "constraints_layer = ConstraintsLayer(constraints_group, 14)\n",
    "print(constraints_layer)\n",
    "pred = torch.rand(1000, 14)\n",
    "updated = constraints_layer(pred)\n",
    "assert constraints_group.coherent_with(updated.numpy()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clayer = ConstraintsLayer(ConstraintsGroup([cons0]), 2)\n",
    "loss_fn = nn.BCELoss()\n",
    "learning_rate = 1e-2\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, betas = (0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, clayer, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):   \n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        pred = clayer(pred, goal=y)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, clayer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct_small, correct_big = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            pred = clayer(pred)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct_small += (torch.where(pred[:, 0] > 0.5, 1., 0.) == y[:, 0]).sum().item()\n",
    "            correct_big += (torch.where(pred[:, 1] > 0.5, 1., 0.) == y[:, 1]).sum().item()\n",
    "    test_loss /= size\n",
    "    correct_small /= size\n",
    "    correct_big /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct_small):>0.1f}%, {(100*correct_big):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing on the Rectangles dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.120966 [    0/10000]\n",
      "loss: 0.137118 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, 92.5%, Avg loss: 0.001982 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.120892 [    0/10000]\n",
      "loss: 0.136976 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, 92.5%, Avg loss: 0.001978 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.120564 [    0/10000]\n",
      "loss: 0.136834 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, 92.5%, Avg loss: 0.001977 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.120483 [    0/10000]\n",
      "loss: 0.136693 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, 92.5%, Avg loss: 0.001974 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.120292 [    0/10000]\n",
      "loss: 0.136554 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, 92.5%, Avg loss: 0.001973 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.120212 [    0/10000]\n",
      "loss: 0.136403 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.7%, Avg loss: 0.001971 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.120128 [    0/10000]\n",
      "loss: 0.136268 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001969 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.120013 [    0/10000]\n",
      "loss: 0.136073 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001968 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.119929 [    0/10000]\n",
      "loss: 0.135938 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001966 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.119845 [    0/10000]\n",
      "loss: 0.135810 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001965 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.119762 [    0/10000]\n",
      "loss: 0.135679 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001963 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.119670 [    0/10000]\n",
      "loss: 0.135550 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001962 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.119601 [    0/10000]\n",
      "loss: 0.135421 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001961 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.119503 [    0/10000]\n",
      "loss: 0.135282 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001958 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.119315 [    0/10000]\n",
      "loss: 0.135144 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001957 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.119233 [    0/10000]\n",
      "loss: 0.135013 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001955 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.119148 [    0/10000]\n",
      "loss: 0.134891 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001954 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.119068 [    0/10000]\n",
      "loss: 0.134770 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001951 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.118830 [    0/10000]\n",
      "loss: 0.134648 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001951 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.118799 [    0/10000]\n",
      "loss: 0.134530 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001949 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.118682 [    0/10000]\n",
      "loss: 0.134413 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001948 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.118603 [    0/10000]\n",
      "loss: 0.134297 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001946 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.118525 [    0/10000]\n",
      "loss: 0.134181 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001945 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.118437 [    0/10000]\n",
      "loss: 0.134071 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001944 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.118346 [    0/10000]\n",
      "loss: 0.133958 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001942 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.118267 [    0/10000]\n",
      "loss: 0.133837 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001941 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.118155 [    0/10000]\n",
      "loss: 0.133725 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, 92.8%, Avg loss: 0.001940 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.118068 [    0/10000]\n",
      "loss: 0.133616 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001939 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.117991 [    0/10000]\n",
      "loss: 0.133508 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001937 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.117914 [    0/10000]\n",
      "loss: 0.133399 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001936 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.117832 [    0/10000]\n",
      "loss: 0.133292 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001935 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.117755 [    0/10000]\n",
      "loss: 0.133185 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001934 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.117679 [    0/10000]\n",
      "loss: 0.133081 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001932 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.117591 [    0/10000]\n",
      "loss: 0.132974 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001931 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.117514 [    0/10000]\n",
      "loss: 0.132870 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001930 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.117455 [    0/10000]\n",
      "loss: 0.132767 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001929 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.117376 [    0/10000]\n",
      "loss: 0.132666 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001928 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.117316 [    0/10000]\n",
      "loss: 0.132564 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001927 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.117239 [    0/10000]\n",
      "loss: 0.132464 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001926 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.117160 [    0/10000]\n",
      "loss: 0.132364 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001925 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.117080 [    0/10000]\n",
      "loss: 0.132266 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001923 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.117004 [    0/10000]\n",
      "loss: 0.132168 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001922 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.116928 [    0/10000]\n",
      "loss: 0.132071 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001921 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.116855 [    0/10000]\n",
      "loss: 0.131974 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001920 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.116782 [    0/10000]\n",
      "loss: 0.131878 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001920 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.116783 [    0/10000]\n",
      "loss: 0.131783 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001919 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.116706 [    0/10000]\n",
      "loss: 0.131691 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001918 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.116632 [    0/10000]\n",
      "loss: 0.131596 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001917 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.116557 [    0/10000]\n",
      "loss: 0.131505 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001916 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.116484 [    0/10000]\n",
      "loss: 0.131415 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001914 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.116410 [    0/10000]\n",
      "loss: 0.131325 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001913 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.116338 [    0/10000]\n",
      "loss: 0.131235 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001912 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.116225 [    0/10000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.131145 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001911 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.116205 [    0/10000]\n",
      "loss: 0.131054 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001910 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.116135 [    0/10000]\n",
      "loss: 0.130966 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001909 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.116067 [    0/10000]\n",
      "loss: 0.130879 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001908 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.115999 [    0/10000]\n",
      "loss: 0.130792 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001908 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.115940 [    0/10000]\n",
      "loss: 0.130705 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001907 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.115874 [    0/10000]\n",
      "loss: 0.130620 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001906 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.115809 [    0/10000]\n",
      "loss: 0.130535 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001905 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.115788 [    0/10000]\n",
      "loss: 0.130444 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001904 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.115720 [    0/10000]\n",
      "loss: 0.130358 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001903 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.115646 [    0/10000]\n",
      "loss: 0.130267 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, 92.8%, Avg loss: 0.001902 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.115581 [    0/10000]\n",
      "loss: 0.130182 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 92.9%, Avg loss: 0.001901 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.115516 [    0/10000]\n",
      "loss: 0.130099 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 92.9%, Avg loss: 0.001900 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.115452 [    0/10000]\n",
      "loss: 0.130015 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 92.9%, Avg loss: 0.001899 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.115383 [    0/10000]\n",
      "loss: 0.129934 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 92.9%, Avg loss: 0.001898 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.115318 [    0/10000]\n",
      "loss: 0.129854 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 92.9%, Avg loss: 0.001897 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.115253 [    0/10000]\n",
      "loss: 0.129774 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 92.9%, Avg loss: 0.001896 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.115189 [    0/10000]\n",
      "loss: 0.129695 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 92.9%, Avg loss: 0.001895 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.115123 [    0/10000]\n",
      "loss: 0.129616 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 92.9%, Avg loss: 0.001894 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.115059 [    0/10000]\n",
      "loss: 0.129537 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 92.9%, Avg loss: 0.001893 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.114982 [    0/10000]\n",
      "loss: 0.129461 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 92.9%, Avg loss: 0.001893 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.114920 [    0/10000]\n",
      "loss: 0.129385 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001892 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.114859 [    0/10000]\n",
      "loss: 0.129296 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001891 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.114797 [    0/10000]\n",
      "loss: 0.129221 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001890 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.114674 [    0/10000]\n",
      "loss: 0.129147 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001889 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.114655 [    0/10000]\n",
      "loss: 0.129073 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001888 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.114596 [    0/10000]\n",
      "loss: 0.129000 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001888 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.114537 [    0/10000]\n",
      "loss: 0.128928 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001887 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.114479 [    0/10000]\n",
      "loss: 0.128856 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001886 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.114422 [    0/10000]\n",
      "loss: 0.128784 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001885 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.114365 [    0/10000]\n",
      "loss: 0.128710 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001884 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.114306 [    0/10000]\n",
      "loss: 0.128640 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001884 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.114249 [    0/10000]\n",
      "loss: 0.128568 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001883 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.114191 [    0/10000]\n",
      "loss: 0.128499 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001882 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.114134 [    0/10000]\n",
      "loss: 0.128430 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001881 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.114077 [    0/10000]\n",
      "loss: 0.128360 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001881 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.114020 [    0/10000]\n",
      "loss: 0.128292 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001880 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.113964 [    0/10000]\n",
      "loss: 0.128225 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001879 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.113909 [    0/10000]\n",
      "loss: 0.128157 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001878 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.113854 [    0/10000]\n",
      "loss: 0.128090 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001878 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.113800 [    0/10000]\n",
      "loss: 0.128024 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001877 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.113746 [    0/10000]\n",
      "loss: 0.127957 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001876 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.113692 [    0/10000]\n",
      "loss: 0.127892 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001876 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.113661 [    0/10000]\n",
      "loss: 0.127813 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001875 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.113605 [    0/10000]\n",
      "loss: 0.127749 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001874 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.113552 [    0/10000]\n",
      "loss: 0.127685 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001873 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.113499 [    0/10000]\n",
      "loss: 0.127621 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001873 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.113446 [    0/10000]\n",
      "loss: 0.127558 [ 6400/10000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, 93.0%, Avg loss: 0.001872 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, clayer, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, clayer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAjXElEQVR4nO2df4xdx3Xfv4dLrvlDpFYiKVFaSiJp0Y5ou5JlRlLttlZku6BU1EKRIpUMt1EhhEgaBUXdBlDjIjUUBGhS1EUDqEnYRrUdNFZkA22JRq7aOLLVupZCOZJlkYpcilpZpG3RFLXUD/5Y/jj9487ZO+/cmfvue/t+7n4/wOLcO3fufbPvx8x3zpyZEVUFIYTELBt2AQghowcrBkJIBVYMhJAKrBgIIRVYMRBCKrBiIIRUaFsxiMhDInJURJ7PXBcR+R0ROSgiz4nIjb0vJiFkkDRRDF8AsKvm+u0Atoe/3QB+d+HFIoQMk7YVg6o+AeB4TZY7AXxJC54EMCUiV/SqgISQwbO8B8+YBvBqdH44pP3IZxSR3ShUBQB8iA6O0UYWcL3dvU3zLIRuYno7uacXMcP9jju+ABxT1Y2d3teLiqExqroHwB4AmBDRlYN8cZJkouaar7h93tS9yzLXUo1A3Wvnrp9vc0+TvBc6uKeTvJ1eb/f8djR5/knglW6e3YuK4QiAq6LzzSGNjDDd/HDtPPfjT12re51+VAzx9RXB+h+ff0Z8buWzeyYSedpheZuU37/vnVQU3ZStKb1Q83sB/IMwOnELgBOqWulGEELGh7aKQUS+DOBWABtE5DCAf4lQGavq7wF4FMAdAA4COAngH/arsKR7cq1zXXchpxBSiiF3rROV0a6sQGfdg/OZa+edXRFdu+CuGV5JAM1b7Pi6/9/aKQj/mikW2uVK0bZiUNW721xXAL+8wHIQQkYIDgwQQioMdFSCDJYmIw45yZ9Ks/MV7jyV5s/ruh++TE3ISf7zNXnadS3q7qnrNrRzWMb/V7tuQd3zmz4jLkO3UDEQQipQMSxCOnHw+RZ9RSKPpU268zivz+Of55+VKmeTVi6nEFIKwl8769JTCmIu87y653uF4JXCQmIV/Gv28rl1UDEQQipQMSwiOglayrXkcYvuFcLKzHnqmrf+WfFrL8S34Fv0uURerxTOurxxy5u75u+te22vIOLPpZPWPhco1WtFkoKKgRBSgYphEZBTCnUBSLmWPKUCzL4r2DWJvKsz9/jn1o1k1JFTCL4lj1v0ucw1s6e7uCelSCxthcvrywzkRyy6URDdjHo0hYqBEFKBimGMaacUUq2z5fEtu9k1KFnt0tZm0lPXcs+v8zHUhQvnRgmstU61/j7tdMam7sndm8rrlYI/T/klFtIi18VW9MrvQMVACKlAxTBmdDLVORVn4Ftwa+GtxV8X3WNpF7trdj6VyGvW+yFSiqETH4MfJfAtuV0/E93zjstj9mTmenwtd0+cN6dEvD8iVgxeRUy4805a/9SoRS8USS/uJ4QsQlgxEEIqsCsxJnTThYhlu0l7G3K0boFJ/0uDnYrusbT1wW6syeu7F/Z61lURe+F4jDPnfUzFKvtxyaDb5y60nCa7Be+487cy6QDwZpt734ny+u6FP091b+ya/ctxNyNO74S64dBuoWIghFSgYhgzUtOivVI4ipdxDlsGVqZGnHGWtLACM9iBrRUFAZSf71zimqdX6z+yYliEnMMWbIMkIxOnnLVugXUTNkX3XJ65Zufr41rKHuiHMHKBDUBrXwfIT1ME8mGLuaGGOC30HU6dbTmtWACYzVxL5X3HpeW6H3H3JjeC8VTfF5LvDFYMI07dUJ5XCj6ceW10br9X8xfYj95+7FcGGy/3bWnTwa6xh/gaAqg6HtpFPMX/QG4lklTF4H9RdU4A92teNRtsOL8snJ9/u7xlNmNPuPNUHl95WJHMbwGU/35qqHS1O8/5IZooh4VCHwMhpAIVw5iQChv2E6LixngtSpUAlI27tf6mDK4Jdos7B4B1l7pEkxCbnAWqwxK5SKe4+5BrluoUg1cOHSiGSvP/emEmTszfgfUhbX3YlPFUeK7t0Rjv1fi6e+xxd24vawMycdoKdw60hpinaDcNu5dQMRBCKlAxjCjtFmKNj314M1A04HGDbo39tmDfHey1wV5tzdr26CbLvMU9xHslgdJ50c63kJI8uSYwtebaGXee8/gBecXgbSwD7PgnhVkV7HSwm6K8r7dmnbfH3fXUVHYTKXHLHH9+KXKh0XV7anQLFQMhpAIrBkJIBXYlxoTUGgu+CzEVXduIUvkDZQ/hvcHuCPaSK13CtSjJdSV8bDRQxi1MWmkuctZKG3/lcl+/c87Gx+Z1fLvVngt9i1RX4k137sceTfMDwDGX9lqwoZ8w8eMy62XheOOx1qyWxftfgfJdSK2BOYX64eluVq7uFioGQkgFKoYRo93W83ELY62PNdZxA74JZYMPlErhhmDXmDK4PlhTDCnnox+mXLXOJQDAhmBt3NJKZ4phubP+OKaJYnDKYXnwPq6LopXWzRZ2Oti5ICfCacUCFefjvDUZ8FqU94eFkSOF3RSuXRye4f2wQHXUNhU8arRb5zKlDi442y1UDISQClQMI0qTVZms9bGWKR493ILWxv+GYNdcFw5uDLZOMVgU1KrLoqcC5XjlVJTZjk0h+HnWKcXQjjrFYO3l2y49Ugzzx7OFmQzOhcuOtdpTkWPCjzWaYjBxFPkY5t9ws68WZlVQEO8+XNg1UUyz36krbu0vRX1MV5M1JXsFFQMhpAIVw5iQC3sGSt9C3OPfhlIEAJFP4aeD3RnsB4I1J8QVcY/4p4K1mGh7BfMnxP52PwphX624xHF6E1KKwdvc2s9AGfXkRjDmnQpBMayKhiWmgyS4/GhhTUHYv355mbWiGC52Nrw9m2bKW1aEIqRa5PVIrw/p/zOvImPV0Sv1QMVACKlAxTCi5EKi4/bX2mtTDPGU6W0ALotbtxszthLQ8L7opi3BWnNpcc9TwV4U5c3FPnfjWzDO1aRZb/y0S0+tfuD9ECdc+jGUhGlmy8MQgwUrXBqGIOKhH/92+KWyExPH1h8KpQ9FiEcPNiKtd0zDeeXQz1adioEQUqFRNS4iuwD8OxTNwH9U1X/lrl8N4Isog7fuV9VHe1vUpUndAq9+NCJWDNuB0n8AlKMPfhTikm3uwpboJpukbT6FqWD9yAPQfvRhoeLUq4d2PgegqipMIWxw5+tR4ueUB9m1PJxfMVNmnXIBCz5wwYYgEmGIl71Y2LPRgMjlqJ817vfh6Ga38Ka0faaITAB4EMDtKL5Od4vIDpftXwB4RFU/COAuAP++1wUlhAyOJpXNTQAOquohVZ0D8DCAO10eRetGRT/sXREJIYOmib6bxnzoBgDgMICbXZ7PAfifIvIrKHxiH089SER2A9gNANJpSZc4KeejKVcTwpvj/FtRDkECZdfB0i65OhxYF8KGJqdR4rsQ5u70Q5K+ZPG1Xvu3U+HSuXTfvbDyn3HpU9E9s8HamOMGZ6N1sVa9UthtwaPonY2pmUyud3PlC+WljUgvDeEnXi10glQTetU9uRvAF1R1M4A7APyhiFSerap7VHWnqu5kxUDI6NKkOj+CVr/W5pAWcy+AXQCgqt8WkZUoqtijvSjkUmaZsynFkHI+YjtaFYOFOl9hPT4blswFMQFl6+inTtdNoe5EKfg8qeHJHJ0ohpXu3A/8xcOudjwV7GywXi1FxxLs9F8WdplbxzmOOrKXDB5FMVnwWvE5xnO0/CJY/rtgLHTCVIomimEfgO0islVEJlE4F/e6PD8A8DEAEJHrUPwvPwEhZCxpW62r6jkRuQ/AYyi6Nw+p6n4ReQDA06q6F8A/BfAfROSfoHBE3qOqo7WDxpiTmkTlA5xWWQN/AoV82BJlnl/+2RSCxUibT8EHMQHtw5xTX5+FDFM2yWutfhO1kRvStPKnwqhtCDanklIrOLr344qgHC6crD7exiNng32ttOvRurK3fb51LoscC13zsdGnFmISHnVpvx4dHwDwkQWWhRAyIjAkesyIWw1r2+Z3nDJnwwkUi6vEa7tdZLrC1of2SsH7E+LjOt8CMmn9+mrZc71CSKX7NG9TE71yU5bqFENGvVz5XGHjqKXZYE0pRGHrExcDa6I9LvxoRJN+f6/2mGBINCGkAhXDGGMtybxiiCf4bETrAENlQpSPUTBbNzGqbsQh91XqVxxDN76LnHJIqYx2to6gNiSEXG86VF4yl7wphdilsxZYHSkGv+evkVvirZdQMRBCKrBiIIRUYFdixGkSvGJdivnZKkDRM4jHviradSpYv+tsnXOtm65Er+nF6+S6FvFxN10Ju9dmbYZ+wbpoociNYQjTPob4M1rb+u7nApnq9pVIpXUDFQMhpAIVw4jia/yzmXQgqt1jb9VqABeldi0w2ySAp11r2U3Y80JpFzader12Dss4PTdJq0mZbIjT1JmtDBV5gaeCI9Kv4QAAK+vnXfnvQGrvXw5XEkL6BhXDiGE1/jJ37lsNoGyfkisDTwLpYKVO9n3oxcSoXtPu+amWPhc+3aSsfjp56jnmp5kK1q8UZRbAWqcY4sc7uWBKwD7fOXdepyK5ExUhpOdQMYwofg9Cv8dAfDy/bGBFOqQWUslNhOpmpGEUvz51PoZcnlSAkyelHOw+U2Fn3PlUsPHiLqEtXhk+2cnyEpa1tv72+bZTCvQxEEIGwihW+STC+xhixWCrB78Jf2AZ6/rbnYzTD2qCVL9oN0U7NSrRZATDLwDjp2ynFncJ96yIloc2zqYVoV+ILjc60UuoGAghFcat6l8y+NGJlI9hNtj5pbLilUTf8rlz9GvR1lEmN3U7da1OLfn3LhcTkoomDYohXgXudOQvKnPMz9rOjU7EMPKRENI3WDEQQiosJf04lvjhylhqmvNxvisRb/PzOoBTkU5d1aRbAaSlcu583OmkS+HT4+MuHLqpvuFb5WcKlL7kky6r3dqrbkMKKgZCSIXF1gQsWlIh0bPB2vKBr8dy4jBanZHTlrupclhKpIYrU9dy93Uy9Bueb2Iu/sxmC6Fn2GJO5ny0T65uElWvoGIghFSgYhhx/LBlKsDJXAvRyoLASwCi9UEwbVOA7QndTC9eCtT5Hdrdk1MK8bPCBCv78CJVN/d2YsQZpajwIdEpGBJNCOkbVAxjgh+dAKqjEi2K4UUAM9H5h8LOzPOeCfoaFk7TKeDRez0XPklzIEQbOf4YrYphNlgf4NTP0QiDioEQUoGKYcxITcs1T/ZL0bVTB4FVL0QJ54KeWG5jGH5qTt0eC0uRdqHR8bVcul8cFmVwgimFyA/0GlpHJUwR+unXdYvB9goqBkJIhaXcJIwVfnQCKFsS65e+El37LoBb/iJK+H/BXnc4HMwGa3tYcnSid3jfQrS9lH1YphReLS95H4P3LdQt5dZrqBgIIRVYMRBCKrArMWbE4a8mLU1yxnOovgfgln1RwvPBXrc/HHwk2GuCnUq8WjcbyC5lvNPRPpljZRbXhXjzROul2PnoJ0/1I/Q5BxUDIaQCm4IxI3Y8Wa1uLUsUK4ODAH5wuDy/+qlwcPuBwl5krsqfCtb2PuBwZefkhidNKcyUWU3Whbc/8j3iNbS4Kef1Rm7S1NADnERkl4i8KCIHReT+TJ6fE5EDIrJfRP6ot8UkhAyStk2CiEwAeBDAJ1BM5t0nIntV9UCUZzuAfw7gI6r6hohc1q8CkxIfJj0bXTsE4Ono/OpvhoPvBvsRczpcH6zttxivaLwU14NsR2pnbMO8AU4xHIu8AybUQrxZrBh+glIlAMMZpjSaKIabABxU1UOqOgfgYQB3ujy/AOBBVX0DAFT1aG+LSQgZJE2agmm0VmyHAdzs8rwHAETkWyh24Pucqv4P/yAR2Q1gNwBIN6VtwAGUfvaligD4ik80+fDXLOF/OTtErrkGmJkZdinaUBcA5neAmA32SGEiX48phVPB1+BX44vXbRnGaITRK424HMB2ALcC2AzgCRH5gKrOxplUdQ+APQAwIaI9eu0WrkG5zcdix/ZANdkX76j+1wF8PDr/Z8Gu+c1w8Gu2N9qvBfvRYLdEd00F22Q7uwUg/WomSLc0+YSPALgqOt+M+apwnsMAnlLVswBeFpHvo6go9oH0Dd/nPBMdH0cZBQ0A/zvYXX8aDu4IU3JuMKeDjU5siu5imHQ9udEIm6h2sDAz0S3hQzFXQ6wY3kKrj2EQS7jlaOJj2Adgu4hsFZFJAHcB2Ovy/FcUagEisgFF1+IQCCFjSduKQVXPAbgPwGMAXgDwiKruF5EHROSTIdtjAF4XkQMAHgfwq6r6evqJhJBRp1FnUVUfBfCoS/v16FgBfCb8kSERdy3eQavPy3yPtz1e2Mk/Cwk3fD0cfCjY6fKm+aHL1BbwwNIcxkwNV1oXYjbY8M6/EeZKxn26cDwTTuOgtLfQukJXbm1Hzq4khAyFpVjlLzpyazXEfbm/DNbinD7x38PBbWFJoRu+ExKuje6aCtYUQxz8tNjxjtfUClc2oGguQ5sh9UqLwYvlHaeCmDCn42z0tJNoVQmDCH3OQcVACKlAxbCI8FOy430Qzd9gc6k+HHwNa8xzdMN/Cwfvj+7yYdJ+u/eYxfpVyikHoFQMs8HaKH4INzffQqQYbKgupRhOo1zXcdhQMRBCKizWan5Jct4dxztHmL/BZr7ZoMTf/i/h4MNBb9z6zfKmyiIufY6AHGkSe0TMt/duevWPQmCzKYVoVMLcDvZ5xCHQZ9Gq+obhWzCoGAghFZZSlb+kuID0rlU2G858DTeGAIdpUw7XP1HedMn7woGFSXtfQ+rrM+5fKT/64JVCtEfE/LIq5lsIy+aZQgjy7M3Xyjssp9/JGij8CymVMIxJVFQMhJAK4169kwznUb8HhXV/bU7Vz381HOyMbvr7NlJhvoaLg00pBj9SMU5frbrJYnWKweIWwmSpt8OYgzlyQvBIPGnIIh1ng03FLRj0MRBCRgpWDISQCuOk90iHpPagsD1VzQlpC2bsCBE3P/3l6Kb3hsSbHgsJtpK0H7b0x2iQPqq0czrGgeYWNhacjqFHAdtMOPTX4uXPrCvnt58Diq7DMByNKagYCCEVxq06Jx2Q2oPCr0pojjELeLr2a+U9l7w3HFwV4qevyA1bxse5iVaj+FVLTYzKKYXZYOPJ7EESzD1XWHM6BvvjEL0U7XQ//xT7HLxiGBWoGAghFUaxGid9wE/htYAnm8xjKz9GggGf+lI4sBU/7wsOiMmpkFDnYxhl5ZALYgLySsGilF6J8oap6jan/XtoOZ8Jp34xFqCcLBWrhFHxLwBUDISQBKNQfZMB4PuvtvS8D5X+v1GeTcGFftt/CgmXBnvPH4SD1NfHWl8bwWi3PNwgaLfoSt1UarfiM54ts775/cLapl5BMfjFWOL9KO3pw9hdqhOoGAghFagYlijWx7XxdOsHx+uW2kjFxaFF/NCekLAy3H3X70e5vTf/3cH6kYxYOcRfv1RYcidfzyZ7YORiFFJTqU0pzAQbYhXwrTKr+RT+ItgwGmEjPTYaMYsSe6Vh7BXRCVQMhJAKrBgIIRXYlVhieGeXOcGsSxFvmWZK2cT/ym8X1lZpwOlohcJP/W5hJ201I9sL07a+s/Ujp6JXiLsVp1H9Osbdg3Zf1SYzJNsFLwFlyLM5G2317LCy1Qtvlllts44w1nvq5cKaI9eHPwPl+91JF8Ja71Hboo4QssSgYljimIKwEN14ZWlr+fyu2meDcrghzmzey7/3lcJe/VJI+Fiw1wcb73S1ITo+hmZrSua+sinF0FQpREsszSsFczYGpfDyDwr7VJTVZqA9W5jcCtDxZsOdDFPa+54bau7nUCcVAyGkAhXDEsW3Np3sZzA/Eev5Mu3W3wwH1uD+nTCGd1uwkz8TLtwSPend0fF+AOvD8UpngfYrU3cyIcr8CG7nKABlAFOQBt8PPgWL/Po/UdaQ5cfBrWKKwcSTCap4MLSXrXw/lQMVAyGkAhXDEqdOOVirYd5184r7oGEAeDXE/d4WgqCmrS9+e7C2zfbNj5c3rdsRPeE/A9gSjlMjGE1Dq08njq2kNmJiazXPBGv+BADHgofAplA/E6z5E54us74Z1JEFhZlvwY9GxO/pBWdjlqG1pfafzSBHJ6gYCCEVqBhIC3FrdNqlWQtmnvV4FyXrV1s/+/owtn9LsJtsFeoPRzfdfKA8fuLLwPZwfMVkONgSZbbQalupOqccYsXgfQphdtOp0KZbEz8T3WLNvy3PZsEcoahHowEMv9GUD4G296fbxVgm3Lnf1fxCIl+v/A1UDISQCqKqQ3nhCRHtx0TcdwCs6cNzx4mTUKyGdHWvb6WAsvWwdnxFsPHntzZYm5lt7bvtSGFiIPYq2PE6y2hLyW0LdkuUeaN7AXtBK4wVPG6eTTxYZ/+4s6YYjqDEBihmwq3HWk5bxi/sNnuMqSZ7/GywcbiHFcVGdqyIh6DYDEku4OtVgD+v8zm8BXxHVXfWZElCxUAIqdCoYhCRXSLyoogcFJH7a/L9rIioiHRcQxFCRoe2zkcRmQDwIIBPoPDe7BORvap6wOVbC+AfozVolIwZdc4rv05hSrWbbDZZPROsxUJ9M7rHuhu/BeDzrwDTQadfGdIvT+RdZ10H80Fav9F3KVIFNR0fvIJzwR6PbjE35XF37rsJQNlVOOHO7WX82gsp4pZ5Aq3dAt9qn4/yxedxvl4NZTZRDDcBOKiqh1R1DsDDAO5M5PsNFJ/x6cQ1QsgY0WS4chqtm+kcBnBznEFEbgRwlar+iYj8au5BIrIbwG4AXbrGSBMEMziJ4TiVu+G3O8lsrf8xZ8ec5ZjBBJoNN+aUA9C7IKgFxzGIyDIAnwdwT7u8qroHwB6gGJVY6GuTNKuwtS/P9SMWXgbH1q75EYxJlKwOdh+AW6NzG3CIR5fWOmt5/ayKFSjxZTrvrI/kjI+9PZnImxthyFmgrNfMWvds1JZ4a1IxHEG5swAAbEbrAM9aAO8H8A0RAYru4F4R+aSqRgGkZNypa83si21f+GXu3H5YceUSVywvRdfsxx1XIisy1g+hxs+cdGm+omiCr0xSwUp+8RX/Y4/ft9wU6lSwUjek/A7d0OT+fQC2i8hWEZkEcBeAvXZRVU+o6gZV3aKqWwA8CYCVAiFjTFvFoKrnROQ+AI+hqNAeUtX9IvIAgKdVdW/9E8hipU5B5FZBjlvcuFWKg4DqWnbf+tepgdy13DNi/GvXteS5AKRulm8bFRj5SPpK3Q/KfgyzaJ1HuZgrBn8t5/eou1YX+eivHe8y8pGTqEhfaaIqgFYl4f0VKXItbOoHnKsQUs/KVSKp5y/UH5CiiXKoG3no1ajEqCkYQsgIwIqBEFKBXQkycnQS5GP4Yb8YP4Tq70ml5fLWdTuQyJN7ndzrpoKV6vL4fIMMiSaELDGoGMiioJtQ4rpRA6Mub9MRktTEqJyKqFMxPngppSDqRlo6gYqBEFKBioEsOTpZF9HHDqRmdVseP1SYuidHk3Dt3BqQKxJpCx1KpWIghFSgYiAkop2PoclCKjkFkaKTgKYm6b0KuqJiIIRUoGIgpIacggD6s4ZC3VwPn95PqBgIIRWoGAjpgH7sLA2ULXRd5KPf3yOXr5flIYSQeVgxEEIqsCtByAJpEmqdoy5E2gc9dbM4TbdQMRBCKlAxENIjulEOfmVp71isI7X5ViqtG6gYCCEVqBgI6THdKAdr6ePhSlMRfvMerwZWJI47UR4pqBgIIRWoGAjpE6kp0Dn1sMzZ+L7cUvMpBWFK4V3Ni1lbHkIImYeKgZA+k1p6zSsHSz+bSPO+hjr/QZM8TaBiIIRUYMVACKnArgQhAyS3JmNq1qZ1K3z3w7oWtvdr6l6uEk0I6TlUDIQMgSbrOlir7Z2PPj0emuROVISQvkHFQMgQ6WRFKD/N+nSw8dCkqYiFKgcqBkJIBSoGQkaIVEvvg5/8+VyU19JOY2E0UgwisktEXhSRgyJyf+L6Z0TkgIg8JyJfF5FrFlguQsgQaVsxiMgEgAcB3A5gB4C7RWSHy/YMgJ2q+lcAfBXAb/e6oIQsZs6j6m+4EP7mwt/Z8GfnpxN/J8OfnXdLE8VwE4CDqnpIVecAPAzgzjiDqj6uqifD6ZMANi+gTISQIdPExzAN4NXo/DCAm2vy3wvga6kLIrIbwG4AkIYFJGQpkZpw5a95X8OZKI+phHcWWI6eOh9F5NMAdgL4aOq6qu4BsAcAJkS0l69NCOkdTSqGIwCuis43h7QWROTjAD4L4KOqesZfJ4SMD00qhn0AtovIVhQVwl0APhVnEJEPAvh9ALtU9WjPS0nIEqRp8FNqX4kVqYwd0Nb5qKrnANwH4DEALwB4RFX3i8gDIvLJkO1fA7gIwFdE5FkR2bvAchFChoioDqerPyGiK9tn65h3AKzpw3NJ/+Bn1gy/E5WFQsfqYHWwa4N9BviOqu7s9LUYEk0IqcCQaELGBO9zmEvkseFK7kRFCOk5VAyEjCl+vwlgwJOoCCFLCyoGQsYMv6BsJ4u9NIWKgRBSgYqBkDGlH0rBoGIghFRgxUAIqcCuBCFjDp2PhJCBQMVAyCKiV+qBioEQUoGKgZBFyEKVAxUDIaTColMMr2DhK+SSwfLKsAtAKiy6isHvhEMI6Rx2JQghFVgxEEIqsGIghFRgxUAIqcCKgRBSgRUDIaQCKwZCSAVWDISQCqwYCCEVWDEQQiqwYiCEVGDFQAipwIqBEFKBFQMhpAIrBkJIBVYMhJAKrBgIIRUaVQwisktEXhSRgyJyf+L6u0Tkj8P1p0RkS89LSggZGG0rBhGZAPAggNtRrJx2t4j4FdTuBfCGql4L4N8C+K1eF5QQMjiaKIabABxU1UOqOgfgYQB3ujx3AvhiOP4qgI+JiPSumISQQdJkMdhpAK9G54cB3JzLo6rnROQEgPUAjsWZRGQ3gN3h9MxJ4PluCj0kNsD9PyPMOJUVGK/yjlNZAeC93dw00FWiVXUPgD0AICJPq+rOQb7+Qhin8o5TWYHxKu84lRUoytvNfU26EkcAXBWdbw5pyTwishzAxQBe76ZAhJDh06Ri2Adgu4hsFZFJAHcB2Ovy7AXw8+H47wL4M1XV3hWTEDJI2nYlgs/gPgCPAZgA8JCq7heRBwA8rap7AfwBgD8UkYMAjqOoPNqxZwHlHgbjVN5xKiswXuUdp7ICXZZX2LATQjyMfCSEVGDFQAip0PeKYZzCqRuU9TMickBEnhORr4vINcMoZ1Se2vJG+X5WRFREhjbM1qSsIvJz4f3dLyJ/NOgyurK0+y5cLSKPi8gz4ftwxzDKGcrykIgcFZFkXJAU/E74X54TkRvbPlRV+/aHwln5EoBtACYBfBfADpfnHwH4vXB8F4A/7meZFljWnwGwOhz/0rDK2rS8Id9aAE8AeBLAzlEtK4DtAJ4BcEk4v2yU31sUTr1fCsc7AMwMsbx/A8CNAJ7PXL8DwNcACIBbADzV7pn9VgzjFE7dtqyq+riqngynT6KI6RgWTd5bAPgNFHNXTg+ycI4mZf0FAA+q6hsAoKpHB1zGmCblVQDrwvHFAH44wPK1FkT1CRSjgTnuBPAlLXgSwJSIXFH3zH5XDKlw6ulcHlU9B8DCqQdNk7LG3IuiFh4WbcsbJONVqvongyxYgibv7XsAvEdEviUiT4rIroGVrkqT8n4OwKdF5DCARwH8ymCK1hWdfrcHGxK9WBCRTwPYCeCjwy5LDhFZBuDzAO4ZclGashxFd+JWFErsCRH5gKrODrNQNdwN4Auq+m9E5K+iiON5v6peGHbBekG/FcM4hVM3KStE5OMAPgvgk6p6ZkBlS9GuvGsBvB/AN0RkBkXfcu+QHJBN3tvDAPaq6llVfRnA91FUFMOgSXnvBfAIAKjqtwGsRDHBahRp9N1uoc9OkeUADgHYitKJ8z6X55fR6nx8ZEgOnCZl/SAKp9T2YZSx0/K6/N/A8JyPTd7bXQC+GI43oJC+60e4vF8DcE84vg6Fj0GG+H3Ygrzz8W+h1fn4522fN4AC34Gi9n8JwGdD2gMoWlygqGm/AuAggD8HsG2Ib267sv4pgNcAPBv+9g6rrE3K6/IOrWJo+N4Kiq7PAQDfA3DXKL+3KEYivhUqjWcB/M0hlvXLAH4E4CwK5XUvgF8E8IvRe/tg+F++1+R7wJBoQkgFRj4SQiqwYiCEVGDFQAipwIqBEFKBFQMhpAIrBkJIBVYMhJAK/x8WH7qaFTFOuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = np.arange(0., 1., 0.01, dtype = \"float32\")\n",
    "ys = np.arange(0., 1., 0.01, dtype = \"float32\")\n",
    "grid = np.array([(x, y) for x in xs for y in ys])\n",
    "grid = torch.from_numpy(grid)\n",
    "\n",
    "probs = model(grid)\n",
    "#probs = clayer(probs)\n",
    "\n",
    "small = probs[:, 0].reshape(len(xs), len(ys)).detach().numpy()\n",
    "large = probs[:, 1].reshape(len(xs), len(ys)).detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(small, cmap='hot', interpolation='nearest', extent=(0., 1., 0., 1.), origin='lower')\n",
    "draw_rectangles(ax, rect0, rect1)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(large, cmap='hot', interpolation='nearest', extent=(0., 1., 0., 1.), origin='lower')\n",
    "draw_rectangles(ax, rect0, rect1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9998692\n"
     ]
    }
   ],
   "source": [
    "print(small.max())\n",
    "print(large.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
